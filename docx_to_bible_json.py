import os
import subprocess
import json
import regex as re
import unicodedata
from pathlib import Path
from docx import Document

# =========================
# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# =========================
INPUT_DIR = r"public/bib"
TEMP_DOCX_DIR = r"temp_docx"
OUTPUT_DIR = r"public/bible-json"

Path(TEMP_DOCX_DIR).mkdir(exist_ok=True)
Path(OUTPUT_DIR).mkdir(exist_ok=True)

# =========================
# ØªØ­ÙˆÙŠÙ„ DOC â†’ DOCX
# =========================
def convert_doc_to_docx():
    docs = list(Path(INPUT_DIR).glob("*.doc"))
    if not docs:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª .doc")
        return False

    print(f"ğŸ”„ ØªØ­ÙˆÙŠÙ„ {len(docs)} Ù…Ù„Ù DOC â†’ DOCX")
    SOFFICE_PATH = r"C:\Program Files\LibreOffice\program\soffice.exe"
    subprocess.run([
        SOFFICE_PATH,
        "--headless",
        "--convert-to", "docx",
        "--outdir", TEMP_DOCX_DIR,
        *[str(f) for f in docs]
    ], check=True)

    return True

# =========================
# ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
# =========================
def normalize_text(text):
    text = unicodedata.normalize("NFKC", text)
    text = re.sub(r"\s+", " ", text)
    text = text.replace("Ù ","0").replace("Ù¡","1").replace("Ù¢","2") \
               .replace("Ù£","3").replace("Ù¤","4").replace("Ù¥","5") \
               .replace("Ù¦","6").replace("Ù§","7").replace("Ù¨","8").replace("Ù©","9")
    return text.strip()

# =========================
# Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù DOCX
# =========================
def read_docx(path):
    doc = Document(path)
    return normalize_text("\n".join(p.text for p in doc.paragraphs))

# =========================
# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£ØµØ­Ø§Ø­Ø§Øª ÙˆØ§Ù„Ø¢ÙŠØ§Øª
# =========================
VERSE_REGEX = re.compile(r"(\d+)\s*([^0-9]+)")

def parse_chapters(text):
    chapters = []
    current = []

    for num, verse in VERSE_REGEX.findall(text):
        current.append({
            "verse": int(num),
            "text_vocalized": verse.strip()
        })

    chapters.append(current)
    return chapters

# =========================
# Ø§Ù„ØªÙ†ÙÙŠØ°
# =========================
if not convert_doc_to_docx():
    exit()

docx_files = list(Path(TEMP_DOCX_DIR).glob("*.docx"))
print(f"ğŸ“– Ù‚Ø±Ø§Ø¡Ø© {len(docx_files)} Ù…Ù„Ù DOCX")

bible = []

for f in docx_files:
    print("ğŸ“˜", f.name)
    text = read_docx(f)

    book_name = f.stem
    chapters = parse_chapters(text)

    bible.append({
        "abbrev": book_name.lower(),
        "name": book_name,
        "chapters": chapters
    })

# =========================
# Ø­ÙØ¸ JSON
# =========================
out_path = Path(OUTPUT_DIR) / "bible.json"
with open(out_path, "w", encoding="utf-8") as f:
    json.dump(bible, f, ensure_ascii=False, indent=2)

print("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ bible.json Ø¨Ù†Ø¬Ø§Ø­")
